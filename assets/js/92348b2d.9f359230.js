"use strict";(self.webpackChunknestjs_toolkit_docs=self.webpackChunknestjs_toolkit_docs||[]).push([[9899],{4229:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>g,frontMatter:()=>i,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"kafka/best-practices","title":"Best Practices - Production Kafka with NestJS","description":"Production-ready best practices for NestJS Kafka applications including message design, consumer patterns, performance optimization, security, and deployment strategies.","source":"@site/docs/kafka/best-practices.md","sourceDirName":"kafka","slug":"/kafka/best-practices","permalink":"/libraries/docs/kafka/best-practices","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Best Practices - Production Kafka with NestJS","description":"Production-ready best practices for NestJS Kafka applications including message design, consumer patterns, performance optimization, security, and deployment strategies.","keywords":["Kafka Best Practices","NestJS Best Practices","Production Kafka","Performance Optimization","Security","Deployment","Message Design"]},"sidebar":"tutorialSidebar","previous":{"title":"Advanced Features - Enterprise Kafka Capabilities","permalink":"/libraries/docs/kafka/advanced-features"},"next":{"title":"NestJS Kafka Client - Enterprise-Grade Integration","permalink":"/libraries/docs/kafka/"}}');var t=s(4848),a=s(8453);const i={title:"Best Practices - Production Kafka with NestJS",description:"Production-ready best practices for NestJS Kafka applications including message design, consumer patterns, performance optimization, security, and deployment strategies.",keywords:["Kafka Best Practices","NestJS Best Practices","Production Kafka","Performance Optimization","Security","Deployment","Message Design"]},o="Best Practices",c={},l=[{value:"Message Design",id:"message-design",level:2},{value:"Use Meaningful Keys",id:"use-meaningful-keys",level:3},{value:"Include Idempotency Keys",id:"include-idempotency-keys",level:3},{value:"Message Schema Evolution",id:"message-schema-evolution",level:3},{value:"Consumer Design Patterns",id:"consumer-design-patterns",level:2},{value:"Batch Processing for High Throughput",id:"batch-processing-for-high-throughput",level:3},{value:"Single Message Processing for Low Latency",id:"single-message-processing-for-low-latency",level:3},{value:"Error Handling Strategy",id:"error-handling-strategy",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Batch Size Tuning",id:"batch-size-tuning",level:3},{value:"Memory Management",id:"memory-management",level:3},{value:"Connection Optimization",id:"connection-optimization",level:3},{value:"Monitoring and Observability",id:"monitoring-and-observability",level:2},{value:"Comprehensive Logging",id:"comprehensive-logging",level:3},{value:"Metrics Collection",id:"metrics-collection",level:3},{value:"Health Checks",id:"health-checks",level:3},{value:"Security Best Practices",id:"security-best-practices",level:2},{value:"Authentication and Authorization",id:"authentication-and-authorization",level:3},{value:"Message Encryption",id:"message-encryption",level:3},{value:"Input Validation",id:"input-validation",level:3},{value:"Deployment Best Practices",id:"deployment-best-practices",level:2},{value:"Environment Configuration",id:"environment-configuration",level:3},{value:"Graceful Shutdown",id:"graceful-shutdown",level:3},{value:"Testing Best Practices",id:"testing-best-practices",level:2},{value:"Unit Testing Consumers",id:"unit-testing-consumers",level:3},{value:"Integration Testing",id:"integration-testing",level:3},{value:"Common Anti-Patterns to Avoid",id:"common-anti-patterns-to-avoid",level:2},{value:"\u274c Don&#39;t Block the Event Loop",id:"-dont-block-the-event-loop",level:3},{value:"\u274c Don&#39;t Ignore Errors",id:"-dont-ignore-errors",level:3},{value:"\u274c Don&#39;t Create Too Many Connections",id:"-dont-create-too-many-connections",level:3},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"best-practices",children:"Best Practices"})}),"\n",(0,t.jsx)(n.p,{children:"This guide covers production-ready best practices for using the NestJS Kafka Client effectively and safely."}),"\n",(0,t.jsx)(n.h2,{id:"message-design",children:"Message Design"}),"\n",(0,t.jsx)(n.h3,{id:"use-meaningful-keys",children:"Use Meaningful Keys"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"// \u2705 Good: Use meaningful keys for partitioning\nawait this.kafkaClient.send('orders', {\n  key: order.customerId, // Groups orders by customer\n  value: JSON.stringify(order),\n});\n\n// \u274c Bad: Random or no keys\nawait this.kafkaClient.send('orders', {\n  key: Math.random().toString(), // Defeats partitioning\n  value: JSON.stringify(order),\n});\n"})}),"\n",(0,t.jsx)(n.h3,{id:"include-idempotency-keys",children:"Include Idempotency Keys"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"// \u2705 Good: Always include idempotency keys for critical operations\nawait this.kafkaClient.send('payments', {\n  key: payment.orderId,\n  value: JSON.stringify(payment),\n  headers: {\n    'idempotency-key': payment.transactionId,\n    'timestamp': new Date().toISOString(),\n    'version': '1.0',\n  },\n});\n"})}),"\n",(0,t.jsx)(n.h3,{id:"message-schema-evolution",children:"Message Schema Evolution"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"// \u2705 Good: Design for schema evolution\ninterface OrderEventV1 {\n  version: '1.0';\n  orderId: string;\n  customerId: string;\n  amount: number;\n  // New fields should be optional\n  currency?: string;\n}\n\ninterface OrderEventV2 {\n  version: '2.0';\n  orderId: string;\n  customerId: string;\n  amount: number;\n  currency: string; // Now required\n  // Always keep backward compatibility\n  items?: OrderItem[];\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"consumer-design-patterns",children:"Consumer Design Patterns"}),"\n",(0,t.jsx)(n.h3,{id:"batch-processing-for-high-throughput",children:"Batch Processing for High Throughput"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"// \u2705 Good: Use batch processing for high-volume topics\n@Consumer('analytics-events', {\n  batch: true,\n  batchSize: 500,\n  batchTimeout: 5000,\n  groupByKey: true,\n})\nexport class AnalyticsConsumer {\n  async handleBatch(messages: KafkaMessage[]) {\n    // Process in chunks to avoid memory issues\n    const chunks = this.chunkArray(messages, 100);\n    \n    for (const chunk of chunks) {\n      await this.processChunk(chunk);\n    }\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"single-message-processing-for-low-latency",children:"Single Message Processing for Low Latency"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"// \u2705 Good: Use single message processing for real-time requirements\n@Consumer('fraud-alerts', {\n  batch: false, // Process immediately\n  maxConcurrency: 10,\n})\nexport class FraudAlertConsumer {\n  async handleMessage(message: KafkaMessage) {\n    const alert = JSON.parse(message.value.toString());\n    \n    // Immediate processing for time-sensitive alerts\n    await this.processFraudAlert(alert);\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"error-handling-strategy",children:"Error Handling Strategy"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"// \u2705 Good: Comprehensive error handling\n@Consumer('orders', {\n  dlq: {\n    topic: 'orders-dlq',\n    maxRetries: 3,\n    retryDelay: (attempt) => Math.min(1000 * Math.pow(2, attempt), 30000),\n    shouldRetry: (error, message, attempt) => {\n      // Don't retry validation errors\n      if (error.name === 'ValidationError') return false;\n      \n      // Don't retry after 3 attempts for business logic errors\n      if (error.name === 'BusinessLogicError' && attempt >= 3) return false;\n      \n      // Retry transient errors\n      return error.name === 'TransientError';\n    },\n  },\n})\nexport class OrderConsumer {\n  private readonly logger = new Logger(OrderConsumer.name);\n\n  async handleMessage(message: KafkaMessage) {\n    try {\n      const order = this.validateOrder(message);\n      await this.processOrder(order);\n    } catch (error) {\n      this.logger.error(`Order processing failed: ${error.message}`, {\n        orderId: message.headers['order-id'],\n        error: error.stack,\n      });\n      throw error; // Let DLQ handle it\n    }\n  }\n\n  private validateOrder(message: KafkaMessage): Order {\n    // Throw ValidationError for invalid messages\n    // These won't be retried\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,t.jsx)(n.h3,{id:"batch-size-tuning",children:"Batch Size Tuning"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"// \u2705 Good: Tune batch sizes based on message size and processing time\n@Consumer('small-messages', {\n  batch: true,\n  batchSize: 1000, // Larger batches for small messages\n  batchTimeout: 2000,\n})\nexport class SmallMessageConsumer {}\n\n@Consumer('large-messages', {\n  batch: true,\n  batchSize: 10, // Smaller batches for large messages\n  batchTimeout: 10000,\n})\nexport class LargeMessageConsumer {}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"memory-management",children:"Memory Management"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"// \u2705 Good: Process large batches in chunks\n@Consumer('large-volume-topic', {\n  batch: true,\n  batchSize: 1000,\n})\nexport class MemoryEfficientConsumer {\n  async handleBatch(messages: KafkaMessage[]) {\n    // Process in smaller chunks to manage memory\n    const chunkSize = 50;\n    \n    for (let i = 0; i < messages.length; i += chunkSize) {\n      const chunk = messages.slice(i, i + chunkSize);\n      await this.processChunk(chunk);\n      \n      // Optional: Force garbage collection for very large batches\n      if (i % 500 === 0) {\n        global.gc?.();\n      }\n    }\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"connection-optimization",children:"Connection Optimization"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"// \u2705 Good: Optimize connection settings for your environment\nKafkaModule.forRoot({\n  clientId: 'my-app',\n  brokers: ['kafka-1:9092', 'kafka-2:9092'],\n  \n  // Optimize for your network conditions\n  connectionTimeout: 3000,\n  requestTimeout: 30000,\n  \n  // Producer optimization\n  producer: {\n    maxInFlightRequests: 5, // Balance throughput vs memory\n    idempotent: true, // Prevent duplicates\n    compression: 'gzip', // Reduce network usage\n  },\n  \n  // Consumer optimization\n  consumer: {\n    sessionTimeout: 30000,\n    heartbeatInterval: 3000,\n    maxBytes: 1048576, // 1MB - adjust based on message size\n  },\n})\n"})}),"\n",(0,t.jsx)(n.h2,{id:"monitoring-and-observability",children:"Monitoring and Observability"}),"\n",(0,t.jsx)(n.h3,{id:"comprehensive-logging",children:"Comprehensive Logging"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"@Consumer('orders')\nexport class OrderConsumer {\n  private readonly logger = new Logger(OrderConsumer.name);\n\n  async handleMessage(message: KafkaMessage) {\n    const startTime = Date.now();\n    const orderId = message.headers['order-id'];\n    \n    this.logger.log(`Processing order ${orderId}`, {\n      partition: message.partition,\n      offset: message.offset,\n    });\n\n    try {\n      await this.processOrder(message);\n      \n      const duration = Date.now() - startTime;\n      this.logger.log(`Order ${orderId} processed successfully in ${duration}ms`);\n    } catch (error) {\n      this.logger.error(`Order ${orderId} processing failed`, {\n        error: error.message,\n        stack: error.stack,\n        partition: message.partition,\n        offset: message.offset,\n      });\n      throw error;\n    }\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"metrics-collection",children:"Metrics Collection"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"@Injectable()\nexport class KafkaMetricsService {\n  private readonly metrics = new Map<string, number>();\n\n  @EventListener('kafka.message.consumed')\n  onMessageConsumed(event: { topic: string; processingTime: number }) {\n    this.incrementCounter(`messages.consumed.${event.topic}`);\n    this.recordHistogram(`processing.time.${event.topic}`, event.processingTime);\n  }\n\n  @EventListener('kafka.error')\n  onError(event: { topic: string; error: Error }) {\n    this.incrementCounter(`errors.${event.topic}.${event.error.name}`);\n  }\n\n  @Cron('0 * * * * *') // Every minute\n  reportMetrics() {\n    // Send metrics to your monitoring system\n    this.sendToMonitoring(Object.fromEntries(this.metrics));\n    this.metrics.clear();\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"health-checks",children:"Health Checks"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"@Controller('health')\nexport class HealthController {\n  constructor(\n    private kafkaHealth: KafkaHealthIndicator,\n    private metricsService: KafkaMetricsService,\n  ) {}\n\n  @Get('kafka')\n  async checkKafka() {\n    const health = await this.kafkaHealth.isHealthy('kafka');\n    const metrics = this.metricsService.getMetrics();\n    \n    return {\n      ...health,\n      metrics: {\n        messagesPerMinute: metrics.messagesConsumed,\n        errorRate: metrics.errors / metrics.messagesConsumed,\n        avgProcessingTime: metrics.avgProcessingTime,\n      },\n    };\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"security-best-practices",children:"Security Best Practices"}),"\n",(0,t.jsx)(n.h3,{id:"authentication-and-authorization",children:"Authentication and Authorization"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"// \u2705 Good: Use strong authentication\nKafkaModule.forRoot({\n  clientId: 'my-app',\n  brokers: ['kafka:9092'],\n  \n  ssl: {\n    rejectUnauthorized: true,\n    ca: [fs.readFileSync('/certs/ca-cert.pem', 'utf-8')],\n    key: fs.readFileSync('/certs/client-key.pem', 'utf-8'),\n    cert: fs.readFileSync('/certs/client-cert.pem', 'utf-8'),\n  },\n  \n  sasl: {\n    mechanism: 'scram-sha-256', // Use strong SASL mechanism\n    username: process.env.KAFKA_USERNAME,\n    password: process.env.KAFKA_PASSWORD,\n  },\n})\n"})}),"\n",(0,t.jsx)(n.h3,{id:"message-encryption",children:"Message Encryption"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"// \u2705 Good: Encrypt sensitive data\n@Injectable()\nexport class SecureOrderService {\n  constructor(\n    private kafkaClient: KafkaClient,\n    private encryptionService: EncryptionService,\n  ) {}\n\n  async createOrder(order: Order) {\n    // Encrypt sensitive fields\n    const encryptedOrder = {\n      ...order,\n      customerData: await this.encryptionService.encrypt(order.customerData),\n      paymentInfo: await this.encryptionService.encrypt(order.paymentInfo),\n    };\n\n    await this.kafkaClient.send('orders', {\n      key: order.customerId,\n      value: JSON.stringify(encryptedOrder),\n      headers: {\n        'encryption-version': '1.0',\n      },\n    });\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"input-validation",children:"Input Validation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"// \u2705 Good: Always validate input\n@Consumer('orders')\nexport class OrderConsumer {\n  async handleMessage(message: KafkaMessage) {\n    // Validate message structure\n    const order = this.validateAndParseOrder(message);\n    \n    // Sanitize input\n    const sanitizedOrder = this.sanitizeOrder(order);\n    \n    await this.processOrder(sanitizedOrder);\n  }\n\n  private validateAndParseOrder(message: KafkaMessage): Order {\n    try {\n      const order = JSON.parse(message.value.toString());\n      \n      // Use a validation library like Joi or class-validator\n      const { error, value } = orderSchema.validate(order);\n      if (error) {\n        throw new ValidationError(`Invalid order: ${error.message}`);\n      }\n      \n      return value;\n    } catch (error) {\n      throw new ValidationError(`Failed to parse order: ${error.message}`);\n    }\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"deployment-best-practices",children:"Deployment Best Practices"}),"\n",(0,t.jsx)(n.h3,{id:"environment-configuration",children:"Environment Configuration"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"// \u2705 Good: Environment-specific configuration\nconst getKafkaConfig = (): KafkaModuleOptions => {\n  const environment = process.env.NODE_ENV;\n  \n  const baseConfig = {\n    clientId: process.env.KAFKA_CLIENT_ID,\n    brokers: process.env.KAFKA_BROKERS.split(','),\n  };\n\n  switch (environment) {\n    case 'development':\n      return {\n        ...baseConfig,\n        logLevel: 'debug',\n        producer: { allowAutoTopicCreation: true },\n      };\n      \n    case 'staging':\n      return {\n        ...baseConfig,\n        logLevel: 'info',\n        ssl: true,\n        sasl: {\n          mechanism: 'scram-sha-256',\n          username: process.env.KAFKA_USERNAME,\n          password: process.env.KAFKA_PASSWORD,\n        },\n      };\n      \n    case 'production':\n      return {\n        ...baseConfig,\n        logLevel: 'warn',\n        ssl: {\n          rejectUnauthorized: true,\n          ca: [fs.readFileSync('/certs/ca-cert.pem', 'utf-8')],\n          key: fs.readFileSync('/certs/client-key.pem', 'utf-8'),\n          cert: fs.readFileSync('/certs/client-cert.pem', 'utf-8'),\n        },\n        sasl: {\n          mechanism: 'scram-sha-256',\n          username: process.env.KAFKA_USERNAME,\n          password: process.env.KAFKA_PASSWORD,\n        },\n        producer: {\n          idempotent: true,\n          maxInFlightRequests: 5,\n        },\n      };\n      \n    default:\n      throw new Error(`Unknown environment: ${environment}`);\n  }\n};\n"})}),"\n",(0,t.jsx)(n.h3,{id:"graceful-shutdown",children:"Graceful Shutdown"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"// \u2705 Good: Implement proper shutdown handling\n@Injectable()\nexport class AppService implements OnApplicationShutdown {\n  constructor(private kafkaClient: KafkaClient) {}\n\n  async onApplicationShutdown(signal?: string) {\n    this.logger.log(`Received shutdown signal: ${signal}`);\n    \n    // Stop accepting new messages\n    await this.kafkaClient.pause();\n    \n    // Wait for in-flight messages to complete\n    await this.waitForInFlightMessages();\n    \n    // Gracefully disconnect\n    await this.kafkaClient.disconnect();\n    \n    this.logger.log('Kafka client shutdown complete');\n  }\n\n  private async waitForInFlightMessages(timeout = 30000): Promise<void> {\n    const start = Date.now();\n    \n    while (this.hasInFlightMessages() && Date.now() - start < timeout) {\n      await new Promise(resolve => setTimeout(resolve, 100));\n    }\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"testing-best-practices",children:"Testing Best Practices"}),"\n",(0,t.jsx)(n.h3,{id:"unit-testing-consumers",children:"Unit Testing Consumers"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"describe('OrderConsumer', () => {\n  let consumer: OrderConsumer;\n  let orderService: jest.Mocked<OrderService>;\n\n  beforeEach(async () => {\n    const module = await Test.createTestingModule({\n      providers: [\n        OrderConsumer,\n        {\n          provide: OrderService,\n          useValue: {\n            processOrder: jest.fn(),\n          },\n        },\n      ],\n    }).compile();\n\n    consumer = module.get<OrderConsumer>(OrderConsumer);\n    orderService = module.get(OrderService);\n  });\n\n  it('should process valid order message', async () => {\n    const message: KafkaMessage = {\n      key: Buffer.from('customer-123'),\n      value: Buffer.from(JSON.stringify({ id: 'order-456' })),\n      headers: {},\n      partition: 0,\n      offset: '100',\n    };\n\n    await consumer.handleMessage(message);\n\n    expect(orderService.processOrder).toHaveBeenCalledWith({ id: 'order-456' });\n  });\n});\n"})}),"\n",(0,t.jsx)(n.h3,{id:"integration-testing",children:"Integration Testing"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"describe('Kafka Integration', () => {\n  let app: INestApplication;\n  let kafkaClient: KafkaClient;\n\n  beforeAll(async () => {\n    const module = await Test.createTestingModule({\n      imports: [\n        KafkaModule.forRoot({\n          clientId: 'test-client',\n          brokers: ['localhost:9092'],\n        }),\n      ],\n    }).compile();\n\n    app = module.createNestApplication();\n    await app.init();\n    \n    kafkaClient = app.get(KafkaClient);\n  });\n\n  it('should send and receive messages', async () => {\n    const testMessage = { id: 'test-123' };\n    \n    // Send message\n    await kafkaClient.send('test-topic', {\n      key: 'test-key',\n      value: JSON.stringify(testMessage),\n    });\n\n    // Verify message was received (implementation depends on your test setup)\n    // This might involve checking a test consumer or database\n  });\n});\n"})}),"\n",(0,t.jsx)(n.h2,{id:"common-anti-patterns-to-avoid",children:"Common Anti-Patterns to Avoid"}),"\n",(0,t.jsx)(n.h3,{id:"-dont-block-the-event-loop",children:"\u274c Don't Block the Event Loop"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"// \u274c Bad: Synchronous processing\n@Consumer('orders')\nexport class BadOrderConsumer {\n  handleMessage(message: KafkaMessage) {\n    // This blocks the event loop\n    const result = this.heavyComputationSync(message);\n    return result;\n  }\n}\n\n// \u2705 Good: Asynchronous processing\n@Consumer('orders')\nexport class GoodOrderConsumer {\n  async handleMessage(message: KafkaMessage) {\n    // Non-blocking async processing\n    const result = await this.heavyComputationAsync(message);\n    return result;\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"-dont-ignore-errors",children:"\u274c Don't Ignore Errors"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"// \u274c Bad: Swallowing errors\n@Consumer('orders')\nexport class BadErrorHandling {\n  async handleMessage(message: KafkaMessage) {\n    try {\n      await this.processOrder(message);\n    } catch (error) {\n      console.log('Error occurred'); // Error is lost\n    }\n  }\n}\n\n// \u2705 Good: Proper error handling\n@Consumer('orders')\nexport class GoodErrorHandling {\n  async handleMessage(message: KafkaMessage) {\n    try {\n      await this.processOrder(message);\n    } catch (error) {\n      this.logger.error('Order processing failed', error);\n      throw error; // Let the framework handle retries/DLQ\n    }\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"-dont-create-too-many-connections",children:"\u274c Don't Create Too Many Connections"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"// \u274c Bad: Creating multiple clients\n@Injectable()\nexport class BadKafkaService {\n  async sendMessage() {\n    const client = new KafkaClient(config); // New connection each time\n    await client.send('topic', message);\n  }\n}\n\n// \u2705 Good: Reuse connections\n@Injectable()\nexport class GoodKafkaService {\n  constructor(private kafkaClient: KafkaClient) {} // Injected singleton\n\n  async sendMessage() {\n    await this.kafkaClient.send('topic', message);\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"./troubleshooting",children:"Troubleshooting Guide"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"./configuration",children:"Configuration Reference"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"./",children:"Back to Overview"})}),"\n"]})]})}function g(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>i,x:()=>o});var r=s(6540);const t={},a=r.createContext(t);function i(e){const n=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);