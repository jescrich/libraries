"use strict";(self.webpackChunknestjs_toolkit_docs=self.webpackChunknestjs_toolkit_docs||[]).push([[8320],{5384:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>u,frontMatter:()=>i,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"kafka/advanced-features","title":"Advanced Features","description":"This section covers the enterprise-grade features that make this Kafka client suitable for production environments.","source":"@site/docs/kafka/advanced-features.md","sourceDirName":"kafka","slug":"/kafka/advanced-features","permalink":"/libraries/docs/kafka/advanced-features","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Kafka Producer","permalink":"/libraries/docs/kafka/producer"},"next":{"title":"Best Practices","permalink":"/libraries/docs/kafka/best-practices"}}');var r=s(4848),t=s(8453);const i={},o="Advanced Features",c={},l=[{value:"Pressure Management",id:"pressure-management",level:2},{value:"Back Pressure",id:"back-pressure",level:3},{value:"Back Pressure Strategies",id:"back-pressure-strategies",level:4},{value:"Front Pressure",id:"front-pressure",level:3},{value:"Idempotency",id:"idempotency",level:2},{value:"Message-Level Idempotency",id:"message-level-idempotency",level:3},{value:"Custom Idempotency Logic",id:"custom-idempotency-logic",level:3},{value:"Dead Letter Queue (DLQ)",id:"dead-letter-queue-dlq",level:2},{value:"Basic DLQ Configuration",id:"basic-dlq-configuration",level:3},{value:"Advanced DLQ with Custom Logic",id:"advanced-dlq-with-custom-logic",level:3},{value:"DLQ Processing",id:"dlq-processing",level:3},{value:"Health Monitoring",id:"health-monitoring",level:2},{value:"Built-in Health Checks",id:"built-in-health-checks",level:3},{value:"Custom Health Metrics",id:"custom-health-metrics",level:3},{value:"Batch Processing &amp; Key Grouping",id:"batch-processing--key-grouping",level:2},{value:"Intelligent Batch Processing",id:"intelligent-batch-processing",level:3},{value:"Custom Key Grouping",id:"custom-key-grouping",level:3},{value:"Connection Management",id:"connection-management",level:2},{value:"Connection Pooling",id:"connection-pooling",level:3},{value:"Failover Configuration",id:"failover-configuration",level:3},{value:"Graceful Shutdown",id:"graceful-shutdown",level:2},{value:"Automatic Graceful Shutdown",id:"automatic-graceful-shutdown",level:3},{value:"Custom Shutdown Logic",id:"custom-shutdown-logic",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Memory Management",id:"memory-management",level:3},{value:"Compression and Serialization",id:"compression-and-serialization",level:3},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"advanced-features",children:"Advanced Features"})}),"\n",(0,r.jsx)(n.p,{children:"This section covers the enterprise-grade features that make this Kafka client suitable for production environments."}),"\n",(0,r.jsx)(n.h2,{id:"pressure-management",children:"Pressure Management"}),"\n",(0,r.jsx)(n.h3,{id:"back-pressure",children:"Back Pressure"}),"\n",(0,r.jsx)(n.p,{children:"Back pressure prevents your application from being overwhelmed when it can't keep up with incoming messages."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"@Consumer('high-load-topic', {\n  batch: true,\n  batchSize: 100,\n  backPressureThreshold: 80, // Pause at 80% capacity\n  backPressureStrategy: 'pause', // or 'drop', 'buffer'\n})\nexport class BackPressureConsumer {\n  async handleBatch(messages: KafkaMessage[]) {\n    // When processing falls behind, consumption automatically pauses\n    // Resumes when capacity is available\n    await this.heavyProcessing(messages);\n  }\n}\n"})}),"\n",(0,r.jsx)(n.h4,{id:"back-pressure-strategies",children:"Back Pressure Strategies"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"// Pause Strategy (Default)\n@Consumer('topic', {\n  backPressureStrategy: 'pause',\n  backPressureThreshold: 80,\n})\n\n// Buffer Strategy - Buffer messages up to a limit\n@Consumer('topic', {\n  backPressureStrategy: 'buffer',\n  backPressureThreshold: 80,\n  bufferSize: 1000,\n})\n\n// Drop Strategy - Drop oldest messages when overwhelmed\n@Consumer('topic', {\n  backPressureStrategy: 'drop',\n  backPressureThreshold: 90,\n})\n"})}),"\n",(0,r.jsx)(n.h3,{id:"front-pressure",children:"Front Pressure"}),"\n",(0,r.jsx)(n.p,{children:"Front pressure manages the flow when Kafka brokers are overwhelmed."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"// Automatic front pressure management\nKafkaModule.forRoot({\n  clientId: 'my-app',\n  brokers: ['localhost:9092'],\n  \n  // Front pressure configuration\n  producer: {\n    maxInFlightRequests: 5,\n    requestTimeout: 30000,\n    retry: {\n      initialRetryTime: 100,\n      retries: 8,\n      multiplier: 2,\n      maxRetryTime: 30000,\n    },\n  },\n  \n  // Circuit breaker for failing brokers\n  circuitBreaker: {\n    threshold: 5,\n    timeout: 60000,\n  },\n})\n"})}),"\n",(0,r.jsx)(n.h2,{id:"idempotency",children:"Idempotency"}),"\n",(0,r.jsx)(n.h3,{id:"message-level-idempotency",children:"Message-Level Idempotency"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"@Consumer('payments', {\n  idempotencyKey: (message) => message.headers['idempotency-key'],\n  idempotencyTtl: 3600000, // 1 hour\n  idempotencyStorage: 'redis', // or 'memory', 'database'\n})\nexport class IdempotentPaymentConsumer {\n  async handleMessage(message: KafkaMessage) {\n    // This will only process once per idempotency key\n    const payment = JSON.parse(message.value.toString());\n    await this.processPayment(payment);\n  }\n}\n"})}),"\n",(0,r.jsx)(n.h3,{id:"custom-idempotency-logic",children:"Custom Idempotency Logic"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"@Consumer('orders', {\n  idempotencyKey: (message) => {\n    const order = JSON.parse(message.value.toString());\n    return `${order.customerId}-${order.timestamp}`;\n  },\n  idempotencyValidator: async (key, message) => {\n    // Custom validation logic\n    const order = JSON.parse(message.value.toString());\n    return !(await this.orderExists(order.id));\n  },\n})\nexport class CustomIdempotencyConsumer {\n  async handleMessage(message: KafkaMessage) {\n    // Custom idempotency logic applied\n  }\n}\n"})}),"\n",(0,r.jsx)(n.h2,{id:"dead-letter-queue-dlq",children:"Dead Letter Queue (DLQ)"}),"\n",(0,r.jsx)(n.h3,{id:"basic-dlq-configuration",children:"Basic DLQ Configuration"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"@Consumer('orders', {\n  dlq: {\n    topic: 'orders-dlq',\n    maxRetries: 3,\n    retryDelay: 1000,\n  }\n})\nexport class OrderConsumer {\n  async handleMessage(message: KafkaMessage) {\n    // If this fails 3 times, message goes to DLQ\n    await this.processOrder(message);\n  }\n}\n"})}),"\n",(0,r.jsx)(n.h3,{id:"advanced-dlq-with-custom-logic",children:"Advanced DLQ with Custom Logic"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"@Consumer('payments', {\n  dlq: {\n    topic: 'payments-dlq',\n    maxRetries: 5,\n    retryDelay: (attempt) => Math.min(1000 * Math.pow(2, attempt), 30000),\n    shouldRetry: (error, message, attempt) => {\n      // Custom retry logic\n      if (error.code === 'TEMPORARY_ERROR') return true;\n      if (error.code === 'VALIDATION_ERROR') return false;\n      return attempt < 3;\n    },\n    onDlq: async (message, error) => {\n      // Custom DLQ handling\n      await this.notifyAdmins(message, error);\n      await this.logFailure(message, error);\n    },\n  }\n})\nexport class AdvancedDlqConsumer {\n  async handleMessage(message: KafkaMessage) {\n    await this.processPayment(message);\n  }\n}\n"})}),"\n",(0,r.jsx)(n.h3,{id:"dlq-processing",children:"DLQ Processing"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"@Consumer('orders-dlq')\nexport class DlqProcessor {\n  async handleMessage(message: KafkaMessage) {\n    // Process failed messages from DLQ\n    const originalMessage = JSON.parse(message.value.toString());\n    const failureReason = message.headers['failure-reason'];\n    \n    // Attempt manual processing or alert administrators\n    await this.handleFailedOrder(originalMessage, failureReason);\n  }\n}\n"})}),"\n",(0,r.jsx)(n.h2,{id:"health-monitoring",children:"Health Monitoring"}),"\n",(0,r.jsx)(n.h3,{id:"built-in-health-checks",children:"Built-in Health Checks"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"import { KafkaHealthIndicator } from '@jescrich/nestjs-kafka-client';\n\n@Controller('health')\nexport class HealthController {\n  constructor(private kafkaHealth: KafkaHealthIndicator) {}\n\n  @Get('kafka')\n  async checkKafka() {\n    return this.kafkaHealth.isHealthy('kafka');\n  }\n\n  @Get('kafka/detailed')\n  async detailedKafkaHealth() {\n    return this.kafkaHealth.getDetailedHealth();\n  }\n}\n"})}),"\n",(0,r.jsx)(n.h3,{id:"custom-health-metrics",children:"Custom Health Metrics"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"@Injectable()\nexport class KafkaMetricsService {\n  private readonly metrics = {\n    messagesProduced: 0,\n    messagesConsumed: 0,\n    errors: 0,\n    avgProcessingTime: 0,\n  };\n\n  @EventListener('kafka.message.produced')\n  onMessageProduced() {\n    this.metrics.messagesProduced++;\n  }\n\n  @EventListener('kafka.message.consumed')\n  onMessageConsumed(event: { processingTime: number }) {\n    this.metrics.messagesConsumed++;\n    this.updateAvgProcessingTime(event.processingTime);\n  }\n\n  @EventListener('kafka.error')\n  onError() {\n    this.metrics.errors++;\n  }\n\n  getMetrics() {\n    return this.metrics;\n  }\n}\n"})}),"\n",(0,r.jsx)(n.h2,{id:"batch-processing--key-grouping",children:"Batch Processing & Key Grouping"}),"\n",(0,r.jsx)(n.h3,{id:"intelligent-batch-processing",children:"Intelligent Batch Processing"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"@Consumer('analytics-events', {\n  batch: true,\n  batchSize: 1000,\n  batchTimeout: 5000,\n  groupByKey: true,\n  keyGroupingStrategy: 'round-robin', // or 'hash', 'custom'\n})\nexport class AnalyticsConsumer {\n  async handleBatch(messages: KafkaMessage[]) {\n    // Messages are automatically grouped by key\n    // Each key group maintains order\n    const eventsByUser = this.groupByUser(messages);\n    \n    // Process each user's events in parallel\n    await Promise.all(\n      Object.entries(eventsByUser).map(([userId, events]) =>\n        this.processUserEvents(userId, events)\n      )\n    );\n  }\n}\n"})}),"\n",(0,r.jsx)(n.h3,{id:"custom-key-grouping",children:"Custom Key Grouping"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"@Consumer('orders', {\n  batch: true,\n  groupByKey: true,\n  keyGroupingStrategy: 'custom',\n  customKeyGrouper: (messages) => {\n    // Custom grouping logic\n    return messages.reduce((groups, msg) => {\n      const order = JSON.parse(msg.value.toString());\n      const region = order.shippingAddress.region;\n      \n      if (!groups[region]) groups[region] = [];\n      groups[region].push(msg);\n      return groups;\n    }, {});\n  },\n})\nexport class RegionalOrderConsumer {\n  async handleBatch(messages: KafkaMessage[]) {\n    // Messages grouped by region\n  }\n}\n"})}),"\n",(0,r.jsx)(n.h2,{id:"connection-management",children:"Connection Management"}),"\n",(0,r.jsx)(n.h3,{id:"connection-pooling",children:"Connection Pooling"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"KafkaModule.forRoot({\n  clientId: 'my-app',\n  brokers: ['localhost:9092'],\n  \n  // Connection pool configuration\n  connectionPool: {\n    maxConnections: 10,\n    idleTimeout: 30000,\n    acquireTimeout: 10000,\n  },\n  \n  // Automatic reconnection\n  reconnection: {\n    enabled: true,\n    maxRetries: 10,\n    retryDelay: 1000,\n  },\n})\n"})}),"\n",(0,r.jsx)(n.h3,{id:"failover-configuration",children:"Failover Configuration"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"KafkaModule.forRoot({\n  brokers: [\n    'kafka-1.example.com:9092',\n    'kafka-2.example.com:9092',\n    'kafka-3.example.com:9092',\n  ],\n  \n  // Failover settings\n  failover: {\n    strategy: 'round-robin', // or 'random', 'priority'\n    healthCheckInterval: 30000,\n    maxFailedAttempts: 3,\n  },\n})\n"})}),"\n",(0,r.jsx)(n.h2,{id:"graceful-shutdown",children:"Graceful Shutdown"}),"\n",(0,r.jsx)(n.h3,{id:"automatic-graceful-shutdown",children:"Automatic Graceful Shutdown"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"@Injectable()\nexport class AppService implements OnApplicationShutdown {\n  constructor(private kafkaClient: KafkaClient) {}\n\n  async onApplicationShutdown(signal?: string) {\n    // Automatic graceful shutdown\n    // - Stops accepting new messages\n    // - Completes processing of in-flight messages\n    // - Commits offsets\n    // - Closes connections\n    \n    await this.kafkaClient.shutdown();\n  }\n}\n"})}),"\n",(0,r.jsx)(n.h3,{id:"custom-shutdown-logic",children:"Custom Shutdown Logic"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"@Consumer('orders', {\n  gracefulShutdown: {\n    timeout: 30000, // 30 seconds to complete processing\n    forceShutdown: true, // Force shutdown after timeout\n  }\n})\nexport class GracefulOrderConsumer {\n  private isShuttingDown = false;\n\n  async handleMessage(message: KafkaMessage) {\n    if (this.isShuttingDown) {\n      // Skip processing during shutdown\n      return;\n    }\n    \n    await this.processOrder(message);\n  }\n\n  @EventListener('kafka.shutdown.start')\n  onShutdownStart() {\n    this.isShuttingDown = true;\n  }\n}\n"})}),"\n",(0,r.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,r.jsx)(n.h3,{id:"memory-management",children:"Memory Management"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"@Consumer('large-messages', {\n  batch: true,\n  batchSize: 100,\n  \n  // Memory management\n  memoryManagement: {\n    maxMemoryUsage: '512MB',\n    gcThreshold: 0.8,\n    streamProcessing: true, // Process without loading all into memory\n  },\n})\nexport class MemoryEfficientConsumer {\n  async handleBatch(messages: KafkaMessage[]) {\n    // Streaming processing for large batches\n    for await (const chunk of this.chunkMessages(messages, 10)) {\n      await this.processChunk(chunk);\n    }\n  }\n}\n"})}),"\n",(0,r.jsx)(n.h3,{id:"compression-and-serialization",children:"Compression and Serialization"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"// Producer with compression\nawait this.kafkaClient.send('topic', {\n  key: 'key',\n  value: largePayload,\n}, {\n  compression: 'gzip',\n  serializer: 'avro',\n});\n\n// Consumer with custom deserialization\n@Consumer('compressed-topic', {\n  deserializer: 'avro',\n  compression: 'gzip',\n})\nexport class CompressedConsumer {\n  async handleMessage(message: KafkaMessage) {\n    // Automatic decompression and deserialization\n  }\n}\n"})}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"./configuration",children:"Review Configuration Options"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"./best-practices",children:"Learn Best Practices"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"./troubleshooting",children:"Troubleshooting Guide"})}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>i,x:()=>o});var a=s(6540);const r={},t=a.createContext(r);function i(e){const n=a.useContext(t);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),a.createElement(t.Provider,{value:n},e.children)}}}]);