"use strict";(self.webpackChunknestjs_toolkit_docs=self.webpackChunknestjs_toolkit_docs||[]).push([[9977],{6420:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>p,frontMatter:()=>s,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"kafka/producer","title":"producer","description":"---","source":"@site/docs/kafka/producer.md","sourceDirName":"kafka","slug":"/kafka/producer","permalink":"/libraries/docs/kafka/producer","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"consumer","permalink":"/libraries/docs/kafka/consumer"},"next":{"title":"Advanced Features - Enterprise Kafka Capabilities","permalink":"/libraries/docs/kafka/advanced-features"}}');var i=r(4848),a=r(8453);const s={sidebar_position:4},o=void 0,c={},d=[{value:"title: Kafka Producer - High-Performance Message Publishing\ndescription: Learn to use the NestJS Kafka producer with intelligent connection management, batch operations, transactions, and front pressure handling for enterprise applications.\nkeywords: [Kafka Producer, NestJS Producer, Message Publishing, Batch Operations, Transactions, Front Pressure, Circuit Breaker]",id:"title-kafka-producer---high-performance-message-publishingdescription-learn-to-use-the-nestjs-kafka-producer-with-intelligent-connection-management-batch-operations-transactions-and-front-pressure-handling-for-enterprise-applicationskeywords-kafka-producer-nestjs-producer-message-publishing-batch-operations-transactions-front-pressure-circuit-breaker",level:2},{value:"Basic Usage",id:"basic-usage",level:2},{value:"Inject the KafkaClient",id:"inject-the-kafkaclient",level:3},{value:"Send Single Messages",id:"send-single-messages",level:3},{value:"Send with Partitioning",id:"send-with-partitioning",level:3},{value:"Batch Operations",id:"batch-operations",level:2},{value:"Send Multiple Messages",id:"send-multiple-messages",level:3},{value:"Send to Multiple Topics",id:"send-to-multiple-topics",level:3},{value:"Advanced Producer Features",id:"advanced-producer-features",level:2},{value:"Transactional Messages",id:"transactional-messages",level:3},{value:"Custom Serialization",id:"custom-serialization",level:3},{value:"Error Handling and Retries",id:"error-handling-and-retries",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Connection Pooling",id:"connection-pooling",level:3},{value:"Compression",id:"compression",level:3},{value:"Monitoring Production",id:"monitoring-production",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Next Steps",id:"next-steps",level:2}];function l(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"title-kafka-producer---high-performance-message-publishingdescription-learn-to-use-the-nestjs-kafka-producer-with-intelligent-connection-management-batch-operations-transactions-and-front-pressure-handling-for-enterprise-applicationskeywords-kafka-producer-nestjs-producer-message-publishing-batch-operations-transactions-front-pressure-circuit-breaker",children:"title: Kafka Producer - High-Performance Message Publishing\ndescription: Learn to use the NestJS Kafka producer with intelligent connection management, batch operations, transactions, and front pressure handling for enterprise applications.\nkeywords: [Kafka Producer, NestJS Producer, Message Publishing, Batch Operations, Transactions, Front Pressure, Circuit Breaker]"}),"\n",(0,i.jsx)(n.h1,{id:"kafka-producer",children:"Kafka Producer"}),"\n",(0,i.jsx)(n.p,{children:"The KafkaClient provides high-performance message production with intelligent connection management and automatic batching capabilities."}),"\n",(0,i.jsx)(n.h2,{id:"basic-usage",children:"Basic Usage"}),"\n",(0,i.jsx)(n.h3,{id:"inject-the-kafkaclient",children:"Inject the KafkaClient"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"import { Injectable } from '@nestjs/common';\nimport { KafkaClient } from '@jescrich/nestjs-kafka-client';\n\n@Injectable()\nexport class OrderService {\n  constructor(private readonly kafkaClient: KafkaClient) {}\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"send-single-messages",children:"Send Single Messages"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"async createOrder(order: Order) {\n  await this.kafkaClient.send('orders', {\n    key: order.customerId, // Messages with same key are processed in order\n    value: JSON.stringify(order),\n    headers: {\n      'idempotency-key': order.id, // Prevents duplicate processing\n      'content-type': 'application/json',\n    },\n  });\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"send-with-partitioning",children:"Send with Partitioning"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"async createOrderWithPartition(order: Order) {\n  await this.kafkaClient.send('orders', {\n    key: order.customerId,\n    value: JSON.stringify(order),\n    partition: this.getPartitionForCustomer(order.customerId),\n  });\n}\n\nprivate getPartitionForCustomer(customerId: string): number {\n  // Simple hash-based partitioning\n  return Math.abs(customerId.hashCode()) % 3;\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"batch-operations",children:"Batch Operations"}),"\n",(0,i.jsx)(n.h3,{id:"send-multiple-messages",children:"Send Multiple Messages"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"async createMultipleOrders(orders: Order[]) {\n  await this.kafkaClient.sendBatch('orders', \n    orders.map(order => ({\n      key: order.customerId,\n      value: JSON.stringify(order),\n      headers: {\n        'idempotency-key': order.id,\n        'timestamp': new Date().toISOString(),\n      },\n    }))\n  );\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"send-to-multiple-topics",children:"Send to Multiple Topics"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"async processOrderWorkflow(order: Order) {\n  const messages = [\n    {\n      topic: 'orders',\n      messages: [{\n        key: order.customerId,\n        value: JSON.stringify(order),\n      }],\n    },\n    {\n      topic: 'inventory',\n      messages: [{\n        key: order.productId,\n        value: JSON.stringify({ \n          productId: order.productId, \n          quantity: order.quantity \n        }),\n      }],\n    },\n    {\n      topic: 'notifications',\n      messages: [{\n        key: order.customerId,\n        value: JSON.stringify({\n          customerId: order.customerId,\n          type: 'order_created',\n          orderId: order.id,\n        }),\n      }],\n    },\n  ];\n\n  await this.kafkaClient.sendBatch(messages);\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"advanced-producer-features",children:"Advanced Producer Features"}),"\n",(0,i.jsx)(n.h3,{id:"transactional-messages",children:"Transactional Messages"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"async processPayment(payment: Payment) {\n  const transaction = await this.kafkaClient.transaction();\n  \n  try {\n    await transaction.send('payments', {\n      key: payment.orderId,\n      value: JSON.stringify(payment),\n    });\n    \n    await transaction.send('orders', {\n      key: payment.orderId,\n      value: JSON.stringify({ \n        orderId: payment.orderId, \n        status: 'paid' \n      }),\n    });\n    \n    await transaction.commit();\n  } catch (error) {\n    await transaction.abort();\n    throw error;\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"custom-serialization",children:"Custom Serialization"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"import { Serializer } from '@jescrich/nestjs-kafka-client';\n\n@Injectable()\nexport class AvroOrderService {\n  constructor(\n    private readonly kafkaClient: KafkaClient,\n    private readonly avroSerializer: Serializer,\n  ) {}\n\n  async createOrder(order: Order) {\n    const serializedValue = await this.avroSerializer.serialize(\n      'order-schema',\n      order\n    );\n\n    await this.kafkaClient.send('orders', {\n      key: order.customerId,\n      value: serializedValue,\n      headers: {\n        'content-type': 'application/avro',\n      },\n    });\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"error-handling-and-retries",children:"Error Handling and Retries"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"async createOrderWithRetry(order: Order) {\n  const maxRetries = 3;\n  let attempt = 0;\n\n  while (attempt < maxRetries) {\n    try {\n      await this.kafkaClient.send('orders', {\n        key: order.customerId,\n        value: JSON.stringify(order),\n        headers: {\n          'retry-attempt': attempt.toString(),\n        },\n      });\n      return; // Success\n    } catch (error) {\n      attempt++;\n      \n      if (attempt >= maxRetries) {\n        // Send to DLQ or handle failure\n        await this.handleFailedOrder(order, error);\n        throw error;\n      }\n      \n      // Exponential backoff\n      await this.delay(Math.pow(2, attempt) * 1000);\n    }\n  }\n}\n\nprivate delay(ms: number): Promise<void> {\n  return new Promise(resolve => setTimeout(resolve, ms));\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,i.jsx)(n.h3,{id:"connection-pooling",children:"Connection Pooling"}),"\n",(0,i.jsx)(n.p,{children:"The KafkaClient automatically manages connection pooling, but you can configure it:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// In your module configuration\nKafkaModule.forRoot({\n  clientId: 'my-app',\n  brokers: ['localhost:9092'],\n  \n  // Producer-specific settings\n  producer: {\n    maxInFlightRequests: 5,\n    idempotent: true,\n    transactionTimeout: 30000,\n  },\n})\n"})}),"\n",(0,i.jsx)(n.h3,{id:"compression",children:"Compression"}),"\n",(0,i.jsx)(n.p,{children:"Enable compression for better throughput:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"await this.kafkaClient.send('large-messages', {\n  key: 'key',\n  value: largeJsonPayload,\n}, {\n  compression: 'gzip', // or 'snappy', 'lz4'\n});\n"})}),"\n",(0,i.jsx)(n.h3,{id:"monitoring-production",children:"Monitoring Production"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"@Injectable()\nexport class OrderService {\n  private readonly logger = new Logger(OrderService.name);\n\n  async createOrder(order: Order) {\n    const startTime = Date.now();\n    \n    try {\n      await this.kafkaClient.send('orders', {\n        key: order.customerId,\n        value: JSON.stringify(order),\n      });\n      \n      const duration = Date.now() - startTime;\n      this.logger.log(`Order sent successfully in ${duration}ms`);\n    } catch (error) {\n      this.logger.error(`Failed to send order: ${error.message}`, error.stack);\n      throw error;\n    }\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Use meaningful keys"})," for proper partitioning and ordering"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Include idempotency keys"})," in headers for critical messages"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Batch related messages"})," for better throughput"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Handle errors gracefully"})," with proper retry logic"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Monitor producer metrics"})," for performance optimization"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Use transactions"})," for multi-topic atomic operations"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"./consumer",children:"Learn about Kafka Consumers"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"./advanced-features",children:"Explore Advanced Features"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"./configuration",children:"Review Configuration Options"})}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>o});var t=r(6540);const i={},a=t.createContext(i);function s(e){const n=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);